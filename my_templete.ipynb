{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kaggleコンペpetfinder　https://www.kaggle.com/c/petfinder-adoption-prediction\n",
    "をfastaiやpytorch Lightningのような\n",
    "ラッパーライブラリなしで実装したノートブック\n",
    "\n",
    "参照\n",
    "https://www.kaggle.com/yasufuminakama/petfinder-efficientnet-b0-starter-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 画像モデル"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from IPython.core.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "\n",
    "import albumentations as transforms\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "import timm\n",
    "import lightgbm as lgb\n",
    "\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "OUTPUT_DIR = './my_model/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    apex=False\n",
    "    debug=False\n",
    "    print_freq=10\n",
    "    num_workers=4\n",
    "    size=384 ##モデルによって変える。\n",
    "    model_name='vit_base_patch16_384' ##モデルによって変える\n",
    "    #patchを軽いモデルを使う。224で統一\n",
    "    #新しい画像タスクがきたら、自分で仮説が建てられるが理想。\n",
    "    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n",
    "    epochs=3\n",
    "    T_max=3 # CosineAnnealingLR\n",
    "    lr=1e-4\n",
    "    min_lr=1e-6\n",
    "    batch_size=16\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    seed=42\n",
    "    target_size=1\n",
    "    target_col='Pawpularity'\n",
    "    n_fold=2\n",
    "    trn_fold=[0, 1]\n",
    "    train=True\n",
    "    grad_cam=True\n",
    "    isTransFormer = True ##モデルによって変える\n",
    "if CFG.debug:\n",
    "    CFG.epochs = 1\n",
    "    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/s16991/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/s16991/petFinder/notebook/wandb/run-20220317_014338-3uvc3bh4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/cashunsukechiba/petfinder_myproject/runs/3uvc3bh4\" target=\"_blank\">vit_base_patch16_384</a></strong> to <a href=\"https://wandb.ai/cashunsukechiba/petfinder_myproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "import wandb\n",
    "wandb.login\n",
    "\n",
    "def class2dict(f):\n",
    "    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n",
    "\n",
    "run = wandb.init(project=\"petfinder_myproject\", \n",
    "                 config=class2dict(CFG),\n",
    "                 name = CFG.model_name,\n",
    "                 job_type=\"train\",\n",
    "                 notes =\"hoge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deta load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>Pawpularity</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0007de18844b0dbbb5e1f607da0606e0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009c66b9439883ba2750fb825e1d7db</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0013fd999caf9a3efe1352ca1b0d937e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0018df346ac9c1d8413cfcc888ca8246</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001dc955e10590d3ca4673f034feeef2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>../input/petfinder-pawpularity-score/train/001...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  0007de18844b0dbbb5e1f607da0606e0              0     1     1     1       0   \n",
       "1  0009c66b9439883ba2750fb825e1d7db              0     1     1     0       0   \n",
       "2  0013fd999caf9a3efe1352ca1b0d937e              0     1     1     1       0   \n",
       "3  0018df346ac9c1d8413cfcc888ca8246              0     1     1     1       0   \n",
       "4  001dc955e10590d3ca4673f034feeef2              0     0     0     1       0   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  Pawpularity  \\\n",
       "0          0      1        0      0          0     0     0           63   \n",
       "1          0      0        0      0          0     0     0           42   \n",
       "2          0      0        0      1          1     0     0           28   \n",
       "3          0      0        0      0          0     0     0           15   \n",
       "4          0      1        0      0          0     0     0           72   \n",
       "\n",
       "                                           file_path  \n",
       "0  ../input/petfinder-pawpularity-score/train/000...  \n",
       "1  ../input/petfinder-pawpularity-score/train/000...  \n",
       "2  ../input/petfinder-pawpularity-score/train/001...  \n",
       "3  ../input/petfinder-pawpularity-score/train/001...  \n",
       "4  ../input/petfinder-pawpularity-score/train/001...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Subject Focus</th>\n",
       "      <th>Eyes</th>\n",
       "      <th>Face</th>\n",
       "      <th>Near</th>\n",
       "      <th>Action</th>\n",
       "      <th>Accessory</th>\n",
       "      <th>Group</th>\n",
       "      <th>Collage</th>\n",
       "      <th>Human</th>\n",
       "      <th>Occlusion</th>\n",
       "      <th>Info</th>\n",
       "      <th>Blur</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4128bae22183829d2b5fea10effdb0c3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43a2262d7738e3d420d453815151079e</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/43a2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e429cead1848a298432a0acad014c9d</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/4e42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80bc3ccafcc51b66303c2c263aa38486</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/80bc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8f49844c382931444e68dffbe20228f4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/petfinder-pawpularity-score/test/8f49...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Id  Subject Focus  Eyes  Face  Near  Action  \\\n",
       "0  4128bae22183829d2b5fea10effdb0c3              1     0     1     0       0   \n",
       "1  43a2262d7738e3d420d453815151079e              0     1     0     0       0   \n",
       "2  4e429cead1848a298432a0acad014c9d              0     0     0     1       0   \n",
       "3  80bc3ccafcc51b66303c2c263aa38486              1     0     1     0       0   \n",
       "4  8f49844c382931444e68dffbe20228f4              1     1     1     0       1   \n",
       "\n",
       "   Accessory  Group  Collage  Human  Occlusion  Info  Blur  \\\n",
       "0          1      1        0      0          1     0     1   \n",
       "1          0      1        1      0          0     0     0   \n",
       "2          1      1        1      0          1     1     1   \n",
       "3          0      0        0      0          0     1     0   \n",
       "4          1      0        1      0          1     1     0   \n",
       "\n",
       "                                           file_path  \n",
       "0  ../input/petfinder-pawpularity-score/test/4128...  \n",
       "1  ../input/petfinder-pawpularity-score/test/43a2...  \n",
       "2  ../input/petfinder-pawpularity-score/test/4e42...  \n",
       "3  ../input/petfinder-pawpularity-score/test/80bc...  \n",
       "4  ../input/petfinder-pawpularity-score/test/8f49...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n",
    "test = pd.read_csv('../input/petfinder-pawpularity-score/test.csv')\n",
    "\n",
    "def get_train_file_path(image_id):\n",
    "    return \"../input/petfinder-pawpularity-score/train/{}.jpg\".format(image_id)\n",
    "\n",
    "def get_test_file_path(image_id):\n",
    "    return \"../input/petfinder-pawpularity-score/test/{}.jpg\".format(image_id)\n",
    "\n",
    "train['file_path'] = train['Id'].apply(get_train_file_path)\n",
    "test['file_path'] = test['Id'].apply(get_test_file_path)\n",
    "\n",
    "display(train.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold  bins\n",
       "0     0        165\n",
       "      1        209\n",
       "      2        551\n",
       "      3       1014\n",
       "      4        941\n",
       "      5        650\n",
       "      6        420\n",
       "      7        267\n",
       "      8        203\n",
       "      9        137\n",
       "      10        99\n",
       "      11        70\n",
       "      12        51\n",
       "      13       179\n",
       "1     0        165\n",
       "      1        209\n",
       "      2        550\n",
       "      3       1015\n",
       "      4        942\n",
       "      5        649\n",
       "      6        419\n",
       "      7        266\n",
       "      8        203\n",
       "      9        137\n",
       "      10        99\n",
       "      11        70\n",
       "      12        52\n",
       "      13       180\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = int(np.floor(1+np.log2(len(train))))\n",
    "train[\"bins\"] = pd.cut(train[CFG.target_col], bins=num_bins, labels=False)\n",
    "Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for n, (train_index, val_index) in enumerate(Fold.split(train, train[\"bins\"])):\n",
    "    train.loc[val_index, 'fold'] = int(n)\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "display(train.groupby(['fold', \"bins\"]).size())\n",
    "train.to_pickle(OUTPUT_DIR+'train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed値を固定\n",
    "def set_seed(seed =42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic =True\n",
    "set_seed(seed=CFG.seed)\n",
    "\n",
    "def get_transforms(*, data):\n",
    "    if data == 'train':\n",
    "        return transforms.Compose([\n",
    "            transforms.RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    elif data == 'valid':\n",
    "        return transforms.Compose([\n",
    "            transforms.Resize(CFG.size, CFG.size),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['file_path'].values\n",
    "        self.labels = df[CFG.target_col].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_names[idx]\n",
    "        #cv2は画像読み込みなどに使われるライブラリ\n",
    "        image = cv2.imread(file_path)\n",
    "        #色空間を変換\n",
    "        #TODO 変換しない場合を実験\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        label = torch.tensor(self.labels[idx]).float()\n",
    "        return image, label\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['file_path'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_names[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)['image']\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train, transform=get_transforms(data='train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained)\n",
    "        self.n_features = self.model.classifier.in_features\n",
    "        self.model.classifier = nn.Identity()\n",
    "        self.fc = nn.Linear(self.n_features, self.cfg.target_size)\n",
    "\n",
    "    def feature(self, image):\n",
    "        feature = self.model(image)\n",
    "        return feature\n",
    "        \n",
    "    def forward(self, image):\n",
    "        feature = self.feature(image)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, cfg, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.model   = timm.create_model(self.cfg.model_name, pretrained=pretrained, num_classes=0, in_chans=3)\n",
    "        num_features = self.model.num_features\n",
    "        self.linear  = nn.Linear(num_features, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        output = self.linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'train.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = init_logger()\n",
    "\n",
    "def get_scheduler(optimizer):\n",
    "        if CFG.scheduler=='ReduceLROnPlateau':\n",
    "            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n",
    "        elif CFG.scheduler=='CosineAnnealingLR':\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n",
    "            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n",
    "        return scheduler\n",
    "\n",
    "def get_RMSE(y_true,y_pred):\n",
    "    ## squared=FalseでRSCMになる。※TrueでMSE\n",
    "    score = mean_squared_error(y_true= y_true ,y_pred=y_pred,squared=False)\n",
    "    return score\n",
    "\n",
    "#RSMEを出力\n",
    "def get_result(result_df):\n",
    "    preds = result_df['preds'].values\n",
    "    labels = result_df[CFG.target_col].values\n",
    "    score = get_RMSE(labels, preds)\n",
    "    LOGGER.info(f'Score: {score:<.4f}')\n",
    "\n",
    "def train_fn(fold,train_loader,model,criterion,optimizer,epoch,scheduler,device):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "    global_step = 0\n",
    "    for step,(images,labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(images)\n",
    "        loss = criterion(y_preds.view(-1), labels)\n",
    "\n",
    "        # record loss\n",
    "        losses.update(loss.item(), batch_size)\n",
    "\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.6f}  '\n",
    "                  .format(epoch+1, step, len(train_loader),                         \n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "        wandb.log({f\"[fold{fold}] loss\": losses.val,\n",
    "                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    #推論モードに切り替え\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    preds = []\n",
    "    for step, (images, labels) in enumerate(valid_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        # compute loss\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(images)\n",
    "        loss = criterion(y_preds.view(-1), labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        # record accuracy\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          ))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(folds, fold):\n",
    "    LOGGER.info(f\"========== fold: {fold} training ==========\")\n",
    "\n",
    "    #dataset\n",
    "    trn_idx = folds[folds['fold'] != fold].index\n",
    "    val_idx = folds[folds['fold'] == fold].index\n",
    "    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n",
    "    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n",
    "    valid_labels = valid_folds[CFG.target_col].values\n",
    "    train_dataset = TrainDataset(train_folds, transform=get_transforms(data='train'))\n",
    "    valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='train'))\n",
    "\n",
    "    #dataloader\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size, \n",
    "                              shuffle=True, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, \n",
    "                              batch_size=CFG.batch_size * 2, #TODO why\n",
    "                              shuffle=False, \n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "    \n",
    "    #model\n",
    "    if (CFG.isTransFormer):\n",
    "        model = TransformerModel(CFG, pretrained=True)\n",
    "    else:\n",
    "        model = CnnModel(CFG, pretrained=True)\n",
    "    model.to(device)\n",
    "    optimizer = Adam(model.parameters(),lr= CFG.lr,weight_decay=CFG.weight_decay,amsgrad=False)\n",
    "    scheduler = get_scheduler(optimizer)\n",
    "    criterion = RMSELoss()\n",
    "\n",
    "    #train loop\n",
    "    best_score = np.inf\n",
    "    best_loss = np.inf\n",
    "    for epoch in range(CFG.epochs):\n",
    "        # train\n",
    "        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "        \n",
    "        # validation\n",
    "        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n",
    "\n",
    "        if isinstance(scheduler, ReduceLROnPlateau):\n",
    "            scheduler.step(avg_val_loss)\n",
    "        elif isinstance(scheduler, CosineAnnealingLR):\n",
    "            scheduler.step()\n",
    "        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n",
    "            scheduler.step()\n",
    "\n",
    "        # scoring\n",
    "        score = get_RMSE(valid_labels, preds)\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n",
    "                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n",
    "                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n",
    "                   f\"[fold{fold}] score\": score})\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(), \n",
    "                        'preds': preds},\n",
    "                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n",
    "        valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth', \n",
    "                                      map_location=torch.device('cpu'))['preds']\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/309] Loss: 40.9563(40.9563) Grad: 115.4972  LR: 0.000100  \n",
      "Epoch: [1][10/309] Loss: 14.9691(22.9311) Grad: 8.1439  LR: 0.000100  \n",
      "Epoch: [1][20/309] Loss: 20.5331(19.7208) Grad: 30.1614  LR: 0.000100  \n",
      "Epoch: [1][30/309] Loss: 19.1791(20.3534) Grad: 12.0582  LR: 0.000100  \n",
      "Epoch: [1][40/309] Loss: 15.9979(20.1841) Grad: 38.4162  LR: 0.000100  \n",
      "Epoch: [1][50/309] Loss: 26.7204(20.2311) Grad: 37.8322  LR: 0.000100  \n",
      "Epoch: [1][60/309] Loss: 15.9938(20.2486) Grad: 5.9179  LR: 0.000100  \n",
      "Epoch: [1][70/309] Loss: 21.7107(20.6126) Grad: 15.6687  LR: 0.000100  \n",
      "Epoch: [1][80/309] Loss: 25.5296(20.7456) Grad: 3.8574  LR: 0.000100  \n",
      "Epoch: [1][90/309] Loss: 12.0143(20.7602) Grad: 16.8634  LR: 0.000100  \n",
      "Epoch: [1][100/309] Loss: 19.1622(20.7453) Grad: 13.0694  LR: 0.000100  \n",
      "Epoch: [1][110/309] Loss: 14.7591(20.6961) Grad: 67.9764  LR: 0.000100  \n",
      "Epoch: [1][120/309] Loss: 14.8744(20.7243) Grad: 14.3581  LR: 0.000100  \n",
      "Epoch: [1][130/309] Loss: 21.2261(20.7300) Grad: 63.1578  LR: 0.000100  \n",
      "Epoch: [1][140/309] Loss: 8.4983(20.6409) Grad: 39.6701  LR: 0.000100  \n",
      "Epoch: [1][150/309] Loss: 20.7128(20.5742) Grad: 7.6576  LR: 0.000100  \n",
      "Epoch: [1][160/309] Loss: 14.0723(20.4508) Grad: 76.7839  LR: 0.000100  \n",
      "Epoch: [1][170/309] Loss: 16.8056(20.4858) Grad: 11.4090  LR: 0.000100  \n",
      "Epoch: [1][180/309] Loss: 24.7082(20.4233) Grad: 7.9197  LR: 0.000100  \n",
      "Epoch: [1][190/309] Loss: 18.3440(20.3989) Grad: 6.5677  LR: 0.000100  \n",
      "Epoch: [1][200/309] Loss: 13.4139(20.3655) Grad: 6.3775  LR: 0.000100  \n",
      "Epoch: [1][210/309] Loss: 15.7430(20.4220) Grad: 9.3935  LR: 0.000100  \n",
      "Epoch: [1][220/309] Loss: 16.8528(20.3606) Grad: 42.6822  LR: 0.000100  \n",
      "Epoch: [1][230/309] Loss: 22.1323(20.3293) Grad: 7.9205  LR: 0.000100  \n",
      "Epoch: [1][240/309] Loss: 25.5358(20.2377) Grad: 60.4026  LR: 0.000100  \n",
      "Epoch: [1][250/309] Loss: 25.2862(20.2808) Grad: 33.7313  LR: 0.000100  \n",
      "Epoch: [1][260/309] Loss: 29.5232(20.3239) Grad: 27.4632  LR: 0.000100  \n",
      "Epoch: [1][270/309] Loss: 21.4551(20.3446) Grad: 7.4396  LR: 0.000100  \n",
      "Epoch: [1][280/309] Loss: 22.6297(20.3301) Grad: 15.5263  LR: 0.000100  \n",
      "Epoch: [1][290/309] Loss: 22.2768(20.2747) Grad: 15.3452  LR: 0.000100  \n",
      "Epoch: [1][300/309] Loss: 21.7937(20.2669) Grad: 3.2803  LR: 0.000100  \n",
      "Epoch: [1][308/309] Loss: 16.6222(20.2658) Grad: 11.6494  LR: 0.000100  \n",
      "EVAL: [0/155] Loss: 26.9764(26.9764) \n",
      "EVAL: [10/155] Loss: 17.8579(19.8619) \n",
      "EVAL: [20/155] Loss: 19.5480(20.0586) \n",
      "EVAL: [30/155] Loss: 21.8063(20.2539) \n",
      "EVAL: [40/155] Loss: 12.4191(20.5799) \n",
      "EVAL: [50/155] Loss: 17.8776(20.4021) \n",
      "EVAL: [60/155] Loss: 15.9639(20.2572) \n",
      "EVAL: [70/155] Loss: 17.3217(20.2119) \n",
      "EVAL: [80/155] Loss: 24.4151(20.2954) \n",
      "EVAL: [90/155] Loss: 20.1272(20.4313) \n",
      "EVAL: [100/155] Loss: 16.1527(20.2271) \n",
      "EVAL: [110/155] Loss: 23.0031(20.3613) \n",
      "EVAL: [120/155] Loss: 20.9375(20.3007) \n",
      "EVAL: [130/155] Loss: 20.6580(20.2458) \n",
      "EVAL: [140/155] Loss: 16.3148(20.2796) \n",
      "EVAL: [150/155] Loss: 20.7984(20.2857) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Score: 20.5572\n",
      "Epoch 1 - Save Best Score: 20.5572 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [154/155] Loss: 24.2303(20.2715) \n",
      "Epoch: [2][0/309] Loss: 15.5271(15.5271) Grad: 6.2308  LR: 0.000057  \n",
      "Epoch: [2][10/309] Loss: 22.3187(20.0092) Grad: 20.1680  LR: 0.000057  \n",
      "Epoch: [2][20/309] Loss: 23.6200(18.8550) Grad: 38.0751  LR: 0.000057  \n",
      "Epoch: [2][30/309] Loss: 23.7360(19.5647) Grad: 14.5748  LR: 0.000057  \n",
      "Epoch: [2][40/309] Loss: 21.7098(19.3731) Grad: 29.0732  LR: 0.000057  \n",
      "Epoch: [2][50/309] Loss: 22.9413(19.6403) Grad: 44.3361  LR: 0.000057  \n",
      "Epoch: [2][60/309] Loss: 17.1746(19.8836) Grad: 9.0463  LR: 0.000057  \n",
      "Epoch: [2][70/309] Loss: 20.9752(19.8699) Grad: 2.7704  LR: 0.000057  \n",
      "Epoch: [2][80/309] Loss: 31.0419(20.0213) Grad: 35.1669  LR: 0.000057  \n",
      "Epoch: [2][90/309] Loss: 22.8653(20.1242) Grad: 24.5363  LR: 0.000057  \n",
      "Epoch: [2][100/309] Loss: 21.1175(20.0584) Grad: 4.5144  LR: 0.000057  \n",
      "Epoch: [2][110/309] Loss: 18.8889(19.7754) Grad: 2.0771  LR: 0.000057  \n",
      "Epoch: [2][120/309] Loss: 27.3046(19.9349) Grad: 27.1084  LR: 0.000057  \n",
      "Epoch: [2][130/309] Loss: 27.7778(20.0759) Grad: 12.2457  LR: 0.000057  \n",
      "Epoch: [2][140/309] Loss: 22.0912(20.0835) Grad: 9.4753  LR: 0.000057  \n",
      "Epoch: [2][150/309] Loss: 30.9147(20.2630) Grad: 45.8517  LR: 0.000057  \n",
      "Epoch: [2][160/309] Loss: 16.4976(20.1625) Grad: 18.1168  LR: 0.000057  \n",
      "Epoch: [2][170/309] Loss: 18.1771(20.1620) Grad: 36.0033  LR: 0.000057  \n",
      "Epoch: [2][180/309] Loss: 15.9835(20.0922) Grad: 5.1973  LR: 0.000057  \n",
      "Epoch: [2][190/309] Loss: 18.8361(20.1756) Grad: 25.7454  LR: 0.000057  \n",
      "Epoch: [2][200/309] Loss: 29.4622(20.2473) Grad: 43.5357  LR: 0.000057  \n",
      "Epoch: [2][210/309] Loss: 25.8588(20.3075) Grad: 5.3206  LR: 0.000057  \n",
      "Epoch: [2][220/309] Loss: 18.9960(20.3278) Grad: 5.5177  LR: 0.000057  \n",
      "Epoch: [2][230/309] Loss: 21.5017(20.1778) Grad: 18.1782  LR: 0.000057  \n",
      "Epoch: [2][240/309] Loss: 19.0056(20.1106) Grad: 38.3067  LR: 0.000057  \n",
      "Epoch: [2][250/309] Loss: 14.4348(20.0824) Grad: 9.3704  LR: 0.000057  \n",
      "Epoch: [2][260/309] Loss: 25.8753(20.1516) Grad: 23.9442  LR: 0.000057  \n",
      "Epoch: [2][270/309] Loss: 18.6402(20.1816) Grad: 1.6528  LR: 0.000057  \n",
      "Epoch: [2][280/309] Loss: 9.2741(20.1187) Grad: 21.2551  LR: 0.000057  \n",
      "Epoch: [2][290/309] Loss: 23.1735(20.0520) Grad: 2.3406  LR: 0.000057  \n",
      "Epoch: [2][300/309] Loss: 24.6571(20.0783) Grad: 34.8636  LR: 0.000057  \n",
      "Epoch: [2][308/309] Loss: 11.7633(20.1050) Grad: 51.6589  LR: 0.000057  \n",
      "EVAL: [0/155] Loss: 27.3728(27.3728) \n",
      "EVAL: [10/155] Loss: 17.9360(19.8931) \n",
      "EVAL: [20/155] Loss: 19.7957(20.0978) \n",
      "EVAL: [30/155] Loss: 21.8328(20.2991) \n",
      "EVAL: [40/155] Loss: 12.1008(20.6408) \n",
      "EVAL: [50/155] Loss: 17.8066(20.4615) \n",
      "EVAL: [60/155] Loss: 15.6320(20.3096) \n",
      "EVAL: [70/155] Loss: 17.3929(20.2549) \n",
      "EVAL: [80/155] Loss: 24.5572(20.3426) \n",
      "EVAL: [90/155] Loss: 20.1595(20.4812) \n",
      "EVAL: [100/155] Loss: 16.1825(20.2712) \n",
      "EVAL: [110/155] Loss: 23.0007(20.4113) \n",
      "EVAL: [120/155] Loss: 20.9458(20.3487) \n",
      "EVAL: [130/155] Loss: 20.5849(20.2916) \n",
      "EVAL: [140/155] Loss: 16.2545(20.3258) \n",
      "EVAL: [150/155] Loss: 21.0181(20.3283) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Score: 20.6199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [154/155] Loss: 24.4794(20.3111) \n",
      "Epoch: [3][0/309] Loss: 18.3126(18.3126) Grad: 33.5994  LR: 0.000009  \n",
      "Epoch: [3][10/309] Loss: 26.8834(19.3991) Grad: 41.3926  LR: 0.000009  \n",
      "Epoch: [3][20/309] Loss: 11.2106(20.1897) Grad: 31.8955  LR: 0.000009  \n",
      "Epoch: [3][30/309] Loss: 20.5341(20.1198) Grad: 35.6712  LR: 0.000009  \n",
      "Epoch: [3][40/309] Loss: 19.0895(20.0846) Grad: 3.3454  LR: 0.000009  \n",
      "Epoch: [3][50/309] Loss: 18.0389(20.1984) Grad: 47.1635  LR: 0.000009  \n",
      "Epoch: [3][60/309] Loss: 22.9509(20.2407) Grad: 6.8617  LR: 0.000009  \n",
      "Epoch: [3][70/309] Loss: 22.0230(20.6640) Grad: 11.1808  LR: 0.000009  \n",
      "Epoch: [3][80/309] Loss: 23.1382(20.7897) Grad: 7.9693  LR: 0.000009  \n",
      "Epoch: [3][90/309] Loss: 24.9964(20.7484) Grad: 33.4506  LR: 0.000009  \n",
      "Epoch: [3][100/309] Loss: 21.9017(20.6569) Grad: 15.5025  LR: 0.000009  \n",
      "Epoch: [3][110/309] Loss: 27.7808(20.5775) Grad: 34.4488  LR: 0.000009  \n",
      "Epoch: [3][120/309] Loss: 25.7004(20.7187) Grad: 29.4125  LR: 0.000009  \n",
      "Epoch: [3][130/309] Loss: 17.7193(20.7811) Grad: 55.9553  LR: 0.000009  \n",
      "Epoch: [3][140/309] Loss: 20.0748(20.7254) Grad: 55.8066  LR: 0.000009  \n",
      "Epoch: [3][150/309] Loss: 18.4639(20.6698) Grad: 21.5830  LR: 0.000009  \n",
      "Epoch: [3][160/309] Loss: 15.8317(20.6327) Grad: 28.2536  LR: 0.000009  \n",
      "Epoch: [3][170/309] Loss: 17.0680(20.6010) Grad: 43.9445  LR: 0.000009  \n",
      "Epoch: [3][180/309] Loss: 14.4129(20.5149) Grad: 22.9623  LR: 0.000009  \n",
      "Epoch: [3][190/309] Loss: 21.8144(20.3577) Grad: 18.1584  LR: 0.000009  \n",
      "Epoch: [3][200/309] Loss: 20.0210(20.5143) Grad: 17.2708  LR: 0.000009  \n",
      "Epoch: [3][210/309] Loss: 12.6052(20.3981) Grad: 49.5211  LR: 0.000009  \n",
      "Epoch: [3][220/309] Loss: 12.5992(20.3581) Grad: 41.5529  LR: 0.000009  \n",
      "Epoch: [3][230/309] Loss: 14.3883(20.3132) Grad: 45.0431  LR: 0.000009  \n",
      "Epoch: [3][240/309] Loss: 20.1683(20.2679) Grad: 1.9032  LR: 0.000009  \n",
      "Epoch: [3][250/309] Loss: 26.0028(20.2215) Grad: 23.6276  LR: 0.000009  \n",
      "Epoch: [3][260/309] Loss: 20.6822(20.1260) Grad: 15.3693  LR: 0.000009  \n",
      "Epoch: [3][270/309] Loss: 20.8416(20.1000) Grad: 10.4648  LR: 0.000009  \n",
      "Epoch: [3][280/309] Loss: 15.1401(20.0666) Grad: 37.4066  LR: 0.000009  \n",
      "Epoch: [3][290/309] Loss: 21.9459(20.1055) Grad: 24.6684  LR: 0.000009  \n",
      "Epoch: [3][300/309] Loss: 17.5064(20.0761) Grad: 42.8449  LR: 0.000009  \n",
      "Epoch: [3][308/309] Loss: 19.3985(20.1068) Grad: 8.7052  LR: 0.000009  \n",
      "EVAL: [0/155] Loss: 26.9033(26.9033) \n",
      "EVAL: [10/155] Loss: 17.8751(19.8915) \n",
      "EVAL: [20/155] Loss: 19.5111(20.0785) \n",
      "EVAL: [30/155] Loss: 21.8476(20.2703) \n",
      "EVAL: [40/155] Loss: 12.5610(20.5917) \n",
      "EVAL: [50/155] Loss: 17.9752(20.4164) \n",
      "EVAL: [60/155] Loss: 16.0906(20.2730) \n",
      "EVAL: [70/155] Loss: 17.3286(20.2307) \n",
      "EVAL: [80/155] Loss: 24.4115(20.3138) \n",
      "EVAL: [90/155] Loss: 20.1739(20.4501) \n",
      "EVAL: [100/155] Loss: 16.1410(20.2455) \n",
      "EVAL: [110/155] Loss: 22.9996(20.3771) \n",
      "EVAL: [120/155] Loss: 20.9748(20.3160) \n",
      "EVAL: [130/155] Loss: 20.6891(20.2606) \n",
      "EVAL: [140/155] Loss: 16.3253(20.2931) \n",
      "EVAL: [150/155] Loss: 20.7647(20.3010) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Score: 20.5664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [154/155] Loss: 24.1027(20.2871) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 0 result ==========\n",
      "Score: 20.5572\n",
      "========== fold: 1 training ==========\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][0/309] Loss: 55.4706(55.4706) Grad: 108.8001  LR: 0.000100  \n",
      "Epoch: [1][10/309] Loss: 22.9156(24.4804) Grad: 17.8810  LR: 0.000100  \n",
      "Epoch: [1][20/309] Loss: 17.9931(20.8846) Grad: 20.1975  LR: 0.000100  \n",
      "Epoch: [1][30/309] Loss: 25.7586(20.6809) Grad: 31.3421  LR: 0.000100  \n",
      "Epoch: [1][40/309] Loss: 25.0464(20.3036) Grad: 48.4105  LR: 0.000100  \n",
      "Epoch: [1][50/309] Loss: 11.3997(20.4164) Grad: 30.5387  LR: 0.000100  \n",
      "Epoch: [1][60/309] Loss: 23.5515(20.5395) Grad: 41.5328  LR: 0.000100  \n",
      "Epoch: [1][70/309] Loss: 15.2077(20.2236) Grad: 29.7966  LR: 0.000100  \n",
      "Epoch: [1][80/309] Loss: 12.7163(19.9686) Grad: 13.5845  LR: 0.000100  \n",
      "Epoch: [1][90/309] Loss: 20.8176(20.3041) Grad: 16.6741  LR: 0.000100  \n",
      "Epoch: [1][100/309] Loss: 24.5126(20.4470) Grad: 4.6033  LR: 0.000100  \n",
      "Epoch: [1][110/309] Loss: 12.2441(20.2497) Grad: 18.8273  LR: 0.000100  \n",
      "Epoch: [1][120/309] Loss: 24.8422(20.2670) Grad: 5.4419  LR: 0.000100  \n",
      "Epoch: [1][130/309] Loss: 18.2978(20.4276) Grad: 32.3869  LR: 0.000100  \n",
      "Epoch: [1][140/309] Loss: 21.1294(20.2550) Grad: 11.4170  LR: 0.000100  \n",
      "Epoch: [1][150/309] Loss: 21.3312(20.3942) Grad: 14.6684  LR: 0.000100  \n",
      "Epoch: [1][160/309] Loss: 21.9416(20.5071) Grad: 6.1490  LR: 0.000100  \n",
      "Epoch: [1][170/309] Loss: 26.4754(20.4874) Grad: 30.4298  LR: 0.000100  \n",
      "Epoch: [1][180/309] Loss: 21.2828(20.5779) Grad: 15.7483  LR: 0.000100  \n",
      "Epoch: [1][190/309] Loss: 22.9441(20.6029) Grad: 10.3653  LR: 0.000100  \n",
      "Epoch: [1][200/309] Loss: 28.3325(20.6117) Grad: 27.9692  LR: 0.000100  \n",
      "Epoch: [1][210/309] Loss: 25.7663(20.6691) Grad: 1.3080  LR: 0.000100  \n",
      "Epoch: [1][220/309] Loss: 16.3052(20.5754) Grad: 39.2214  LR: 0.000100  \n",
      "Epoch: [1][230/309] Loss: 24.6753(20.4751) Grad: 2.3723  LR: 0.000100  \n",
      "Epoch: [1][240/309] Loss: 25.3426(20.4726) Grad: 32.7169  LR: 0.000100  \n",
      "Epoch: [1][250/309] Loss: 23.0036(20.5323) Grad: 8.1541  LR: 0.000100  \n",
      "Epoch: [1][260/309] Loss: 16.6427(20.5289) Grad: 5.0778  LR: 0.000100  \n",
      "Epoch: [1][270/309] Loss: 27.5480(20.4991) Grad: 34.0481  LR: 0.000100  \n",
      "Epoch: [1][280/309] Loss: 13.7233(20.4217) Grad: 55.1611  LR: 0.000100  \n",
      "Epoch: [1][290/309] Loss: 20.6582(20.4081) Grad: 6.8953  LR: 0.000100  \n",
      "Epoch: [1][300/309] Loss: 21.3722(20.3284) Grad: 15.6481  LR: 0.000100  \n",
      "Epoch: [1][308/309] Loss: 11.9857(20.3019) Grad: 35.6137  LR: 0.000100  \n",
      "EVAL: [0/155] Loss: 16.2965(16.2965) \n",
      "EVAL: [10/155] Loss: 23.0438(19.8140) \n",
      "EVAL: [20/155] Loss: 16.8218(20.4611) \n",
      "EVAL: [30/155] Loss: 24.0224(20.7216) \n",
      "EVAL: [40/155] Loss: 23.7744(21.0121) \n",
      "EVAL: [50/155] Loss: 22.3661(21.1575) \n",
      "EVAL: [60/155] Loss: 18.9957(20.8475) \n",
      "EVAL: [70/155] Loss: 19.4150(20.6905) \n",
      "EVAL: [80/155] Loss: 20.6986(20.7056) \n",
      "EVAL: [90/155] Loss: 21.7629(20.6436) \n",
      "EVAL: [100/155] Loss: 24.8283(20.7248) \n",
      "EVAL: [110/155] Loss: 22.4578(20.6977) \n",
      "EVAL: [120/155] Loss: 19.7317(20.6249) \n",
      "EVAL: [130/155] Loss: 23.6400(20.5995) \n",
      "EVAL: [140/155] Loss: 24.2388(20.4876) \n",
      "EVAL: [150/155] Loss: 19.4977(20.4586) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Score: 20.7246\n",
      "Epoch 1 - Save Best Score: 20.7246 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [154/155] Loss: 16.6484(20.4292) \n",
      "Epoch: [2][0/309] Loss: 14.8811(14.8811) Grad: 1.6648  LR: 0.000057  \n",
      "Epoch: [2][10/309] Loss: 23.1767(21.9926) Grad: 13.0090  LR: 0.000057  \n",
      "Epoch: [2][20/309] Loss: 19.5196(20.9036) Grad: 5.0022  LR: 0.000057  \n",
      "Epoch: [2][30/309] Loss: 30.8264(20.5226) Grad: 19.2064  LR: 0.000057  \n",
      "Epoch: [2][40/309] Loss: 27.3808(21.2055) Grad: 4.8163  LR: 0.000057  \n",
      "Epoch: [2][50/309] Loss: 26.5930(20.7895) Grad: 8.9521  LR: 0.000057  \n",
      "Epoch: [2][60/309] Loss: 14.6562(20.4159) Grad: 47.6483  LR: 0.000057  \n",
      "Epoch: [2][70/309] Loss: 16.0197(19.8375) Grad: 1.5303  LR: 0.000057  \n",
      "Epoch: [2][80/309] Loss: 13.6879(20.3906) Grad: 21.7188  LR: 0.000057  \n",
      "Epoch: [2][90/309] Loss: 18.6622(20.2955) Grad: 19.3825  LR: 0.000057  \n",
      "Epoch: [2][100/309] Loss: 21.1405(20.2703) Grad: 4.3577  LR: 0.000057  \n",
      "Epoch: [2][110/309] Loss: 21.0965(20.2345) Grad: 13.5792  LR: 0.000057  \n",
      "Epoch: [2][120/309] Loss: 33.9515(20.3140) Grad: 28.3671  LR: 0.000057  \n",
      "Epoch: [2][130/309] Loss: 16.2645(20.2028) Grad: 2.4714  LR: 0.000057  \n",
      "Epoch: [2][140/309] Loss: 17.8943(20.3049) Grad: 2.9338  LR: 0.000057  \n",
      "Epoch: [2][150/309] Loss: 16.3266(20.1951) Grad: 8.4465  LR: 0.000057  \n",
      "Epoch: [2][160/309] Loss: 17.5218(20.2674) Grad: 2.1108  LR: 0.000057  \n",
      "Epoch: [2][170/309] Loss: 16.5821(20.1796) Grad: 36.1621  LR: 0.000057  \n",
      "Epoch: [2][180/309] Loss: 21.7078(20.1658) Grad: 1.5666  LR: 0.000057  \n",
      "Epoch: [2][190/309] Loss: 26.1847(20.2747) Grad: 29.2296  LR: 0.000057  \n",
      "Epoch: [2][200/309] Loss: 20.5455(20.2450) Grad: 5.0773  LR: 0.000057  \n",
      "Epoch: [2][210/309] Loss: 19.5547(20.2575) Grad: 27.4514  LR: 0.000057  \n",
      "Epoch: [2][220/309] Loss: 18.2896(20.2808) Grad: 17.4284  LR: 0.000057  \n",
      "Epoch: [2][230/309] Loss: 16.4595(20.2122) Grad: 12.6470  LR: 0.000057  \n",
      "Epoch: [2][240/309] Loss: 16.9346(20.1729) Grad: 32.9740  LR: 0.000057  \n",
      "Epoch: [2][250/309] Loss: 24.0227(20.1496) Grad: 6.1692  LR: 0.000057  \n",
      "Epoch: [2][260/309] Loss: 14.1423(20.0662) Grad: 36.9373  LR: 0.000057  \n",
      "Epoch: [2][270/309] Loss: 23.7344(20.1435) Grad: 6.9363  LR: 0.000057  \n",
      "Epoch: [2][280/309] Loss: 20.0781(20.1027) Grad: 14.0433  LR: 0.000057  \n",
      "Epoch: [2][290/309] Loss: 23.9712(20.0384) Grad: 2.6670  LR: 0.000057  \n",
      "Epoch: [2][300/309] Loss: 16.0509(19.9826) Grad: 40.0623  LR: 0.000057  \n",
      "Epoch: [2][308/309] Loss: 22.0956(20.0685) Grad: 29.4331  LR: 0.000057  \n",
      "EVAL: [0/155] Loss: 16.6011(16.6011) \n",
      "EVAL: [10/155] Loss: 22.1698(19.7910) \n",
      "EVAL: [20/155] Loss: 16.8346(20.4993) \n",
      "EVAL: [30/155] Loss: 23.5056(20.7578) \n",
      "EVAL: [40/155] Loss: 22.8459(21.0045) \n",
      "EVAL: [50/155] Loss: 22.9646(21.1278) \n",
      "EVAL: [60/155] Loss: 18.8885(20.8438) \n",
      "EVAL: [70/155] Loss: 19.4357(20.6722) \n",
      "EVAL: [80/155] Loss: 21.1574(20.6715) \n",
      "EVAL: [90/155] Loss: 21.3018(20.6374) \n",
      "EVAL: [100/155] Loss: 24.1129(20.6965) \n",
      "EVAL: [110/155] Loss: 21.8964(20.6799) \n",
      "EVAL: [120/155] Loss: 19.5853(20.5981) \n",
      "EVAL: [130/155] Loss: 22.9845(20.5624) \n",
      "EVAL: [140/155] Loss: 22.9752(20.4642) \n",
      "EVAL: [150/155] Loss: 19.6972(20.4244) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 - Score: 20.6279\n",
      "Epoch 2 - Save Best Score: 20.6279 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [154/155] Loss: 16.0046(20.3982) \n",
      "Epoch: [3][0/309] Loss: 18.3292(18.3292) Grad: 12.1954  LR: 0.000009  \n",
      "Epoch: [3][10/309] Loss: 18.3132(20.3441) Grad: 28.8518  LR: 0.000009  \n",
      "Epoch: [3][20/309] Loss: 16.0191(19.6298) Grad: 56.8585  LR: 0.000009  \n",
      "Epoch: [3][30/309] Loss: 21.3882(20.7735) Grad: 6.4347  LR: 0.000009  \n",
      "Epoch: [3][40/309] Loss: 16.1304(20.2514) Grad: 40.9553  LR: 0.000009  \n",
      "Epoch: [3][50/309] Loss: 13.8550(20.0264) Grad: 50.3714  LR: 0.000009  \n",
      "Epoch: [3][60/309] Loss: 18.6488(19.8688) Grad: 25.6726  LR: 0.000009  \n",
      "Epoch: [3][70/309] Loss: 12.3197(19.4535) Grad: 21.3180  LR: 0.000009  \n",
      "Epoch: [3][80/309] Loss: 25.0489(19.6737) Grad: 1.7405  LR: 0.000009  \n",
      "Epoch: [3][90/309] Loss: 16.4351(19.4678) Grad: 10.6402  LR: 0.000009  \n",
      "Epoch: [3][100/309] Loss: 24.0592(19.6555) Grad: 10.8113  LR: 0.000009  \n",
      "Epoch: [3][110/309] Loss: 21.2910(19.7282) Grad: 27.4502  LR: 0.000009  \n",
      "Epoch: [3][120/309] Loss: 19.8717(19.6742) Grad: 24.0379  LR: 0.000009  \n",
      "Epoch: [3][130/309] Loss: 14.9038(19.8817) Grad: 34.0608  LR: 0.000009  \n",
      "Epoch: [3][140/309] Loss: 24.8385(20.0245) Grad: 5.5424  LR: 0.000009  \n",
      "Epoch: [3][150/309] Loss: 22.0811(20.0382) Grad: 16.8982  LR: 0.000009  \n",
      "Epoch: [3][160/309] Loss: 14.0664(19.7673) Grad: 11.0479  LR: 0.000009  \n",
      "Epoch: [3][170/309] Loss: 18.5450(19.7622) Grad: 22.6455  LR: 0.000009  \n",
      "Epoch: [3][180/309] Loss: 15.9576(19.8668) Grad: 26.7394  LR: 0.000009  \n",
      "Epoch: [3][190/309] Loss: 17.3653(19.9977) Grad: 17.0795  LR: 0.000009  \n",
      "Epoch: [3][200/309] Loss: 21.2237(20.0551) Grad: 3.6787  LR: 0.000009  \n",
      "Epoch: [3][210/309] Loss: 23.6504(20.0879) Grad: 22.1529  LR: 0.000009  \n",
      "Epoch: [3][220/309] Loss: 22.6143(20.1694) Grad: 22.4295  LR: 0.000009  \n",
      "Epoch: [3][230/309] Loss: 21.2191(20.1951) Grad: 40.6154  LR: 0.000009  \n",
      "Epoch: [3][240/309] Loss: 21.7774(20.0854) Grad: 11.8082  LR: 0.000009  \n",
      "Epoch: [3][250/309] Loss: 22.0614(20.1439) Grad: 26.6298  LR: 0.000009  \n",
      "Epoch: [3][260/309] Loss: 29.0885(20.1684) Grad: 24.5236  LR: 0.000009  \n",
      "Epoch: [3][270/309] Loss: 27.3314(20.1698) Grad: 28.2848  LR: 0.000009  \n",
      "Epoch: [3][280/309] Loss: 20.2939(20.1153) Grad: 6.5615  LR: 0.000009  \n",
      "Epoch: [3][290/309] Loss: 11.6386(20.0145) Grad: 21.8214  LR: 0.000009  \n",
      "Epoch: [3][300/309] Loss: 14.4503(20.0249) Grad: 45.3456  LR: 0.000009  \n",
      "Epoch: [3][308/309] Loss: 19.3644(19.9860) Grad: 9.6595  LR: 0.000009  \n",
      "EVAL: [0/155] Loss: 16.7943(16.7943) \n",
      "EVAL: [10/155] Loss: 22.1162(19.7503) \n",
      "EVAL: [20/155] Loss: 16.4170(20.4003) \n",
      "EVAL: [30/155] Loss: 23.4526(20.6465) \n",
      "EVAL: [40/155] Loss: 22.9570(20.8764) \n",
      "EVAL: [50/155] Loss: 23.2364(21.0157) \n",
      "EVAL: [60/155] Loss: 18.6546(20.7217) \n",
      "EVAL: [70/155] Loss: 19.3190(20.5617) \n",
      "EVAL: [80/155] Loss: 20.9185(20.5763) \n",
      "EVAL: [90/155] Loss: 21.3906(20.5500) \n",
      "EVAL: [100/155] Loss: 23.9414(20.6123) \n",
      "EVAL: [110/155] Loss: 22.1614(20.6026) \n",
      "EVAL: [120/155] Loss: 19.2113(20.5208) \n",
      "EVAL: [130/155] Loss: 22.7423(20.4806) \n",
      "EVAL: [140/155] Loss: 22.8467(20.3819) \n",
      "EVAL: [150/155] Loss: 19.3893(20.3416) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 - Score: 20.5519\n",
      "Epoch 3 - Save Best Score: 20.5519 Model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVAL: [154/155] Loss: 16.2492(20.3152) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "========== fold: 1 result ==========\n",
      "Score: 20.5519\n",
      "========== CV ==========\n",
      "Score: 20.5545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab7f6fb7e974e17b728185e2e19412a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_val_loss</td><td>▁█▄</td></tr><tr><td>[fold0] epoch</td><td>▁▅█</td></tr><tr><td>[fold0] loss</td><td>▂▃▄▅▂▄▄▆▅█▁▄▅▂▃▅▅▅▃▆▄▅▆▁▃▂█▃▄▂▃▃▂▄▂▅▃▄▃▄</td></tr><tr><td>[fold0] lr</td><td>█████████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold0] score</td><td>▁█▂</td></tr><tr><td>[fold1] avg_val_loss</td><td>█▆▁</td></tr><tr><td>[fold1] epoch</td><td>▁▅█</td></tr><tr><td>[fold1] loss</td><td>▃▁▄▃▂▂▅▄▂▅▄▂▂▂▂▃▄▃▂▄▃▅▃▃▄▂▃▃▂▄▂▄▅▁█▁▄▃▁▄</td></tr><tr><td>[fold1] lr</td><td>█████████████▅▅▅▅▅▅▅▅▅▅▅▅▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>[fold1] score</td><td>█▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>[fold0] avg_val_loss</td><td>20.28713</td></tr><tr><td>[fold0] epoch</td><td>3</td></tr><tr><td>[fold0] loss</td><td>19.39846</td></tr><tr><td>[fold0] lr</td><td>1e-05</td></tr><tr><td>[fold0] score</td><td>20.5664</td></tr><tr><td>[fold1] avg_val_loss</td><td>20.31516</td></tr><tr><td>[fold1] epoch</td><td>3</td></tr><tr><td>[fold1] loss</td><td>19.3644</td></tr><tr><td>[fold1] lr</td><td>1e-05</td></tr><tr><td>[fold1] score</td><td>20.55193</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vit_base_patch16_384</strong>: <a href=\"https://wandb.ai/cashunsukechiba/petfinder_myproject/runs/3uvc3bh4\" target=\"_blank\">https://wandb.ai/cashunsukechiba/petfinder_myproject/runs/3uvc3bh4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220317_014338-3uvc3bh4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    if CFG.train:\n",
    "        # train \n",
    "        oof_df = pd.DataFrame()\n",
    "        for fold in range(CFG.n_fold):\n",
    "            if fold in CFG.trn_fold:\n",
    "                _oof_df = train_loop(train, fold)\n",
    "                oof_df = pd.concat([oof_df, _oof_df])\n",
    "                LOGGER.info(f\"========== fold: {fold} result ==========\")\n",
    "                get_result(_oof_df)\n",
    "        LOGGER.info(f\"========== CV ==========\")\n",
    "        get_result(oof_df)\n",
    "        #結果を保存\n",
    "        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n",
    "    wandb.finish()\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training　LGB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### directory設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OUTPUT_DIR = './my_model/'\n",
    "#TODO\n",
    "MODEL_DIR = './my_model/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN_CFG:\n",
    "    num_workers=4\n",
    "    size=224\n",
    "    batch_size=16\n",
    "    model_name='tf_efficientnet_b0_ns'\n",
    "    seed=42\n",
    "    target_size=1\n",
    "    target_col='Pawpularity'\n",
    "    n_fold=2\n",
    "\n",
    "class LGM_CFG:\n",
    "    objective= 'regression'\n",
    "    metric =  'rmse'\n",
    "    boosting_type = 'gbdt'\n",
    "    learning_rate =  0.01\n",
    "    seed = 42\n",
    "    max_depth = -1\n",
    "    min_data_in_leaf =  10\n",
    "    verbosity = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# wandb\n",
    "# ====================================================\n",
    "import wandb\n",
    "wandb.login\n",
    "\n",
    "def class3dict(f):\n",
    "    param = dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__') or name == '__annotations__')\n",
    "    for key,value in param['__annotations__'].items():\n",
    "      param[key] = value\n",
    "    param.pop('__annotations__')\n",
    "    return param\n",
    "lgb_param  = class3dict(LGM_CFG)\n",
    "\n",
    "run = wandb.init(project=\"petfinder_myproject\", \n",
    "                 config= lgb_param,\n",
    "                 name = \"LBGM+\"+CNN_CFG.model_name,\n",
    "                 job_type=\"train\",\n",
    "                 notes =\"hoge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('./my_model/train.pkl')\n",
    "\n",
    "display(train.groupby(['fold', \"bins\"]).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_lightgbm(param, train, features, target, fold=0, categorical=[]):\n",
    "    #dataload\n",
    "    train[[f\"img_{i}\" for i in np.arange(1280)]] = IMG_FEATURES[fold]\n",
    "    trn_idx = train[train.fold != fold].index\n",
    "    val_idx = train[train.fold == fold].index\n",
    "    LOGGER.info(f'train size : {len(trn_idx)}  valid size : {len(val_idx)}')\n",
    "    if categorical == []:\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features].values, label=target.iloc[trn_idx].values)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features].values, label=target.iloc[val_idx].values)\n",
    "    else:\n",
    "        trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx].values, categorical_feature=categorical)\n",
    "        val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx].values, categorical_feature=categorical)\n",
    "    num_round = 10000\n",
    "\n",
    "    #train\n",
    "    clf = lgb.train(param, \n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=10,\n",
    "                    early_stopping_rounds=10)\n",
    "    LOGGER.info(f'Dumping model with pickle... lightgbm_fold{fold}.pkl')\n",
    "    with open(OUTPUT_DIR+f'lightgbm_fold{fold}.pkl', 'wb') as fout:\n",
    "        #モデルをシリアライズ化して保存\n",
    "        pickle.dump(clf, fout)\n",
    "    \n",
    "    #予測\n",
    "    oof = np.zeros(len(train))\n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    score = get_RMSE(target.iloc[val_idx].values, oof[val_idx])\n",
    "    LOGGER.info(f\"fold{fold} score: {score:<.5f}\")\n",
    "    \n",
    "    #future_importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold\n",
    "\n",
    "    return oof, fold_importance_df, val_idx\n",
    "\n",
    "\n",
    "def run_kfold_lightgbm(param, train, features, target, n_fold=5, categorical=[]):\n",
    "    oof = np.zeros(len(train))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    val_idxes = []\n",
    "    \n",
    "    for fold in range(n_fold):\n",
    "        LOGGER.info(f\"===== Fold {fold} =====\")\n",
    "        _oof, fold_importance_df, val_idx = run_single_lightgbm(param, \n",
    "                                                                train, features, target, \n",
    "                                                                fold=fold, categorical=categorical)\n",
    "        oof += _oof\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        val_idxes.append(val_idx)\n",
    "    \n",
    "    val_idxes = np.concatenate(val_idxes)\n",
    "    score = get_RMSE(target.iloc[val_idxes].values, oof[val_idxes])\n",
    "    LOGGER.info(f\"CV score: {score:<.5f}\")\n",
    "    \n",
    "    return oof, feature_importance_df, val_idxes\n",
    "\n",
    "\n",
    "def show_feature_importance(feature_importance_df):\n",
    "    cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "                .groupby(\"Feature\").mean().sort_values(by=\"importance\", ascending=False)[:50].index)\n",
    "    best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "    plt.figure(figsize=(8, 16))\n",
    "    sns.barplot(x=\"importance\", y=\"Feature\", data=best_features.sort_values(by=\"importance\",ascending=False))\n",
    "    plt.title('Features importance (averaged/folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR+'feature_importance_df_lightgbm.png')\n",
    "\n",
    "def get_features(test_loader, model, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    tk0 = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for step, (images) in tk0:\n",
    "        images = images.to(device)\n",
    "        batch_size = images.size(0)\n",
    "        with torch.no_grad():\n",
    "            feature = model.feature(images)\n",
    "        features.append(feature.to('cpu').numpy())\n",
    "    features = np.concatenate(features)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FEATURES = []\n",
    "test_dataset = TestDataset(train, transform=get_transforms(data='valid'))\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=CFG.batch_size * 2, #why?\n",
    "                         shuffle=False, \n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "for fold in range(CFG.n_fold):\n",
    "    model = CnnModel(CFG, pretrained=False)\n",
    "    state = torch.load(MODEL_DIR+f'{CFG.model_name}_fold{fold}_best.pth', \n",
    "                       map_location=torch.device('cpu'))['model']\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)\n",
    "    features = get_features(test_loader, model, device)\n",
    "    IMG_FEATURES.append(features)\n",
    "    del state; gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train['Pawpularity']\n",
    "features = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "            'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'] + [f\"img_{i}\" for i in np.arange(1280)]\n",
    "\n",
    "\n",
    "oof, feature_importance_df, _ = run_kfold_lightgbm(lgb_param, \n",
    "                                                   train, features, target, \n",
    "                                                   n_fold=2, categorical=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_feature_importance(feature_importance_df)\n",
    "feature_importance_df.to_csv(OUTPUT_DIR+f'feature_importance_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pred'] = oof\n",
    "score = get_RMSE(train['Pawpularity'].values, train['pred'].values)\n",
    "LOGGER.info(f\"CV: {score:<.5f}\")\n",
    "train[['Id', 'Pawpularity', 'pred']].to_pickle(OUTPUT_DIR+'oof.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_file_path(image_id):\n",
    "    return \"../input/petfinder-pawpularity-score/test/{}.jpg\".format(image_id)\n",
    "\n",
    "test['file_path'] = test['Id'].apply(get_test_file_path)\n",
    "\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './my_model/'\n",
    "MODEL_DIR = './my_model/'\n",
    "LGB_MODEL_DIR = './my_model//'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    num_workers=4\n",
    "    size=512\n",
    "    batch_size=16\n",
    "    model_name='tf_efficientnet_b0_ns'\n",
    "    seed=42\n",
    "    target_size=1\n",
    "    target_col='Pawpularity'\n",
    "    n_fold=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_single_lightgbm(test, features, model_path, fold):\n",
    "    test[[f\"img_{i}\" for i in np.arange(1280)]] = IMG_FEATURES[fold]\n",
    "    with open(model_path, 'rb') as fin:\n",
    "        clf = pickle.load(fin)\n",
    "    prediction = clf.predict(test[features], num_iteration=clf.best_iteration)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_FEATURES = []\n",
    "test_dataset = TestDataset(test, transform=get_transforms(data='valid'))\n",
    "test_loader = DataLoader(test_dataset, \n",
    "                         batch_size=CFG.batch_size * 2, \n",
    "                         shuffle=False, \n",
    "                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "for fold in range(CFG.n_fold):\n",
    "    model = CnnModel(CFG, pretrained=False)\n",
    "    state = torch.load(MODEL_DIR+f'{CFG.model_name}_fold{fold}_best.pth', \n",
    "                       map_location=torch.device('cpu'))['model']\n",
    "    model.load_state_dict(state)\n",
    "    model.to(device)\n",
    "    features = get_features(test_loader, model, device)\n",
    "    IMG_FEATURES.append(features)\n",
    "    del state; gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n",
    "            'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur'] + [f\"img_{i}\" for i in np.arange(1280)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = [(fold, LGB_MODEL_DIR+f'lightgbm_fold{fold}.pkl') for fold in range(2)]\n",
    "predictions = [inference_single_lightgbm(test, features, model_path, fold) for fold, model_path in model_paths]\n",
    "predictions = np.mean(predictions, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Pawpularity'] = predictions\n",
    "test[['Id', 'Pawpularity']].to_csv('submission.csv', index=False)\n",
    "display(test[['Id', 'Pawpularity']].head())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
